# Secure Cooperation between TEEs

## Heterogenous TEEs

Heterougenous TEEs have been well studied in recent years, e.g., GPU TEEs like Graviton, HIX, H100, Graphcore IPU Trusted Extensions (ITX), FPGA TEEs like SGX-FPGA, ShEF, TEEOD and others like Iceclave, SecNDP, PIM-Enclave. The premise of TEEs is the ability to accomplish minimal computations. In the beginning, the heterogeneous devices used to undertake the tasks in the untrusted environment. However, applying heterogeneous devices to trusted environment directly brings security concerns. That's why we need heterougenous TEEs to extend the trust computing base of CPU TEEs.

The basis of TEEs comes from hardware features and firmware for access control, encryption and communication. The paradigm usually contains the hardware to isolate confidential data and code and record the measurement of booting process and initial states. Most heterougenous TEEs follows the CPU-centered manner and rely on CPU TEE to dispatch concrete tasks. The communication should be encrypted because only TEEs are trusted. Interestingly, these TEEs have similar operations of blocking PCIe bus and DMA accesses. There exists a similar design of secure datapath (e.g., secure PCIe), HETEE [^5], which proposes a specific FPGA design to enforce strong isolation between vulunrable accelerators.
<!-- root of trust: hardware feature and firmware for access control, encryption and communication -->
<!-- specialized instructions -->

This report introduces a common design prototype of them and discuss the chances to optimize them.

### Cost Analysis

The attestation procedure builds a chain of trust across users, CPU TEEs and heterogeneous TEEs but the communication overheads are not well balanced. Generally, the communication between users and CPUs is not frequent but suffers from low bandwidth. On the contrary, the data transfers between CPU and heterogeneous devices are frequent and fast by high bandwidth PCIe bus. CPU TEEs and heterogeneous TEEs are connected through encrypted data stream, so encryption can be a bottleneck. Typical 

<!-- PCIe, DMA -->
<!-- X86 adopts the independent addressing method to separate the memory operation from the peripheral IO operation, so that there is a distinction between the memory space and the IO space. The instructions for accessing memory and peripheral registers within the X86 platform CPU are also different. -->

## Memory Encryption: Counter Mode

AES-CTR (Counter mode) is a member of AES cryptography family which turns a block cipher into a stream cipher. It generates the next keystream block by encrypting successive values of a "counter". The counter can be any function which produces a sequence which is guaranteed not to repeat for a long time, although an actual increment-by-one counter is the simplest and most popular [^1]. Counter mode can encrypt and tranfer data blocks in parallel and decrypt them as the same manner. Therefore, AES-CTR can be accelerated better than other AES variants.
|![encryption](./assets/CTR_encryption_2.svg)|
|:--:|
| *Counter mode encryption* |
|![decryption](./assets/CTR_decryption_2.svg)|
| *Counter mode decryption* |

Block ciphers can be extracted from block groups or generated by cryptographically secure pseudorandom number generators (CSPRNGs). Synthetic Initialization Vector (SIV) is a block cipher mode of operation [^2]. It takes a key, a plaintext, and multiple variable-length octet strings that will be authenticated but not encrypted. It produces a ciphertext having the same length as the plaintext and a synthetic initialization vector. SIV achieves either the goal of deterministic authenticated encryption or the goal of nonce-based, misuse-resistant authenticated encryption.

## PRNG mode

After users build trust with TEEs by the attestation, the communication between TEEs can be a performance bottleneck. Hardware features like AES-NI can be a good solution, but there is still an another option. Let the TEEs negotiate a PRNG seed, they can generate the same OTP keys which have the same length of the plaintext. Then the XOR operation can deal with the encryption and decryption.

Unlike symmetric encryption which takes multiple operations, the PRNG mode can generate the keys ahead and decrypt the ciphertext faster.

## MGX

As elaborated in MGX, data blocks in memory should be encrypted and randomization required to prevent comparing two blocks for confidentiality concern and a memory read must return the most recent value for integrity wherever it is stored [^3].
|![counter](./assets/mem-enc-counter-mode.png)|
|:--:|
| *Memory Encryption: Counter Mode* |

Previous techniques introduce AES counter mode for memory encryption which uses *(address, version number)* as seed to produce One-Time-Pad (OTP) keys and encrypts data [^4][^3]. The version number (VN) are managed by a Merkle Tree for integrity verification. Therefore, MGX stores the metadata (VNs and MACs) in the off-chip memory cache-line by cache-line and verifies the VNs recursively while fetching the data.

MGX observes that the memory access patterns and granularity can be largely determined for a particular application [^3]. For example, data accesses to NN models happen at a coarser granularity, i.e., layer, which cut down the overhead of integrity verification significantly.

*Coarse-grain storage?* It is quite similar to the well-studied Object Storage Service (OSS). In OSS scenario, the object is stored in multiple devices and need to be verified. This gives an impression of trusted environment intuitively. The only difference seems to be that the data need extra encryption and a version number should be set to avoid replay attacks.

There is an another interesting question: how to cache/store billions of objects in SGX? Would it be quite different from untrusted environment? In untrusted environment, Kangaroo [^6] points out the flaws of prior designs which require a large amount of DRAM (log-structure caches) or too many flash writes (set-associative caches) and indicates the proper design to cache billions of tiny objects. It designs a hybrid cache which contains a tiny DRAM cache in the first level, a small on-flash log-structured cache with an in-DRAM index in the second level and a large on-flash set-associative cache. However, caching a single object in TEE are much more expensive. We need some practical practice to cut down the number of objects. Similar to the operator fusion in TVM, we may combine some tiny objects into bigger ones. But how to determine the size and when to write them to the flash?

## Secure PCIe

What if the isolation is enforced by the hardware on the PCIe? Take the HETEE for an example [^5]. HETEE enclave (known as secure controller) first establishes trust with the user through remote attestation and builds a secure communication channel by symmetric keys. The unmodified devices are naturally isolated from each other and the secure PCIe prevents the data interference on different devices.
|![hetee](./assets/hetee.png)|
|:--:|
| *HETEE Overview* |

HETEE also adopts the dynamic mode switch across secure/insecure world similar to ARM TrustZone. The secure mode blocks unauthorized access to accelerators and all requests have to be forwarded to the secure controller first. Then the secure controller decrypts the messages and delivers them to heterogeneous devices.

In HETEE, the devices are exclusive for different users to alleviate security concerns. However, this inevitably brings a great waste of resources and make it hard to balance different tasks. Recall that NVIDIA H100 designs secure Multi-Instance GPU (MIG) to construct hardware firewalls between GPU instances to protect confidentiality and data integrity. Nevertheless, secure PCIe cannot achieve such isolation by hardware features on it, because there is no hardware isolation inside heterogeneous devices.

How to abstract the untrusted devices and construct disjoint trust computing base through secure PCIe? It is quite hard without hardware extensions or natural isolation. If there exist some small computing units which are physically isolated from each other, the enclave can control a subset of them. However, the scenario is too specific.

Acutually, the secure PCIe can make simple secure I/O operations easier. SGX-PFS suffers a lot from integrity check overhead. If we assume that the adversary cannot access the disk physically (i.e., steal the disk), the enclave can directly write data into the disk like untrusted environment. The access control should be enforced by secure PCIe to avoid illegal access to the space of other enclaves. The main benifit is the elimination of encryption cost and verification cost.

## References

[^1]: https://en.wikipedia.org/wiki/Block_cipher_mode_of_operation.
[^2]: Harkins, D. (2008). Synthetic initialization vector (siv) authenticated encryption using the advanced encryption standard (aes) (No. rfc5297).
[^3]: Hua, W., Umar, M., Zhang, Z., & Suh, G. E. (2022, June). MGX: near-zero overhead memory protection for data-intensive accelerators. In Proceedings of the 49th Annual International Symposium on Computer Architecture (pp. 726-741).
[^4]: Gueron, S. (2016). Memory encryption for general-purpose processors. IEEE Security & Privacy, 14(6), 54-62.
[^5]: Zhu, J., Hou, R., Wang, X., Wang, W., Cao, J., Zhao, B., ... & Meng, D. (2020, May). Enabling rack-scale confidential computing using heterogeneous trusted execution environment. In 2020 IEEE Symposium on Security and Privacy (SP) (pp. 1450-1465). IEEE.
[^6]: McAllister, S., Berg, B., Tutuncu-Macias, J., Yang, J., Gunasekar, S., Lu, J., ... & Ganger, G. R. (2021, October). Kangaroo: Caching billions of tiny objects on flash. In Proceedings of the ACM SIGOPS 28th Symposium on Operating Systems Principles (pp. 243-262).
